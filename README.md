If github in unable to render a Jupyter notebook, copy the link of the notebook and enter into the nbviewer:
https://nbviewer.jupyter.org/

## Logistic Regression: A Comparative Understanding

In this notebook series, we study the Logistic Regression classifier model by performing following comparisons.

- Binary vs multi-class classification
- Batch Gradient Descent vs Stochastic Gradient Descent algorithms
- Multi-class classification: One-vs-all vs Softmax regression
- Regularization: L2/L1 vs early stopping



1. Logistic Regression: Binary Classification using Batch Gradient Descent

       -- In this notebook, we use Scikit-Learn's Batch Gradient Descent algorithm for Logistic Regression to perform binary classification. 
      
       -- We visually analyze the decision boundaries. 
       
2. Logistic Regression: Binary Classification using Stochastic Gradient Descent

       -- In this notebook, we use Scikit-Learn's Stochastic Gradient Descent algorithm for Logistic Regression to perform binary classification. 
      
3. Logistic Regression: Multi-class Classification using Batch Gradient Descent

       -- In this notebook, we use Scikit-Learn's Batch Gradient Descent algorithm for Logistic Regression to perform multi-class classification. We study two strategies for multi-class classification: One-vesus-all (OvA) & Multinomial (Softmax)
      

4. Logistic Regression: Multi-class Classification using Stochastic Gradient Descent

       -- In this notebook, we apply the Stochastic Gradient Descent (SGD) algorithm for solving a multi-class classification problem using Logistic Regression. 
      
       -- We study the impact of two types of regularization: L2/L1 & Early Stopping
      
5. Logistic Regression: Comparison With Other Models

       -- In this notebook, we compare the Logistic Regression classifier model with two other classifier models: K-nearest Neighbors & Naive Bayes classifier.
      
6. Logistic Regression: Gradient Descent Optimization Techniques

       -- In this notebook, we learn how to optimize a Logistic Regression classifier. We use a large dataset to reveal the benefit of optimization techniques. We investigate the following two optimization techniques: Optimization Algorithms (solvers) & Dimensionality Reduction
      
      
7. Unconstrained Optimization Algorithms: How To

       -- Scikit-Learn LogisticRegression model uses various algorithms for the optimizing the Gradient Descent algorithm. In this notebook we try to understand how to use some of the optimization algorithms.


      
      
      
